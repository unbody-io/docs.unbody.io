import Collapse from '@/components/Collapse'
import { Tabs } from "nextra/components"


# Similarity Search

Find similar content across text, images, and records based on their characteristics and patterns.

## Text Similarity
A simple example showing semantic text search. The `.similar.text()` method is used on the `textBlock` collection to fetch content similar to "artificial intelligence", with a certainty threshold of 0.8 ensuring high relevance.

<Tabs items={['Unbody SDK', 'GraphQL']}>
  <Tabs.Tab>
    ```typescript
    const data = await unbody.get.textBlock
        .similar
        .text("artificial intelligence", {
            certainty: 0.8
        })
        .exec();
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```graphql
    {
      Get {
        TextDocument(
          nearText: {
            concepts: ["resume"],
            certainty: 0.8
          }
        ) {
          _additional {
            certainty
            distance
          }
          createdAt
          html
          mimeType
          modifiedAt
          originalName
          path
          pathString
          remoteId
          sourceId
          subtitle
          description
          tags
          text
          title
          properties
          toc
          authors
        }
      }
    }
    ```
  </Tabs.Tab>
</Tabs>

<Collapse title="Response">
```typescript

[
    {
        "_additional": {
            "certainty": 0.8059042096138,
            "distance": 0.38819158
        },
        "classNames": [],
        "footnotes": [],
        "html": "<p>Artificial intelligence is a field which helps computer system to be intelligent and take decisions.\nMachine learning helps to implement Artificial Intelligence on the system and deep learning helps to achieve machine learning goals on the system more systematically.\nFigure 1 shows it pictorially.</p>",
        "order": 15,
        "remoteId": null,
        "sourceId": "8ee10ec5-8c3a-4fca-ad68-0255f14a6594",
        "tagName": "p",
        "text": "\nArtificial intelligence is a field which helps computer system to be intelligent and take decisions.\nMachine learning helps to implement Artificial Intelligence on the system and deep learning helps to achieve machine learning goals on the system more systematically.\nFigure 1 shows it pictorially."
    }
]
```
</Collapse>

## Advanced Text Similarity
Here we showcase advanced text similarity search with concept steering. Using the `.similar.text()` method on the `textDocument` collection, we search with multiple concepts while limiting results to 2 entries and maintaining a minimum certainty of 0.65.

<Tabs items={['Unbody SDK', 'GraphQL']}>
  <Tabs.Tab>
    ```typescript
    const {
      data: { payload },
    } = await unbody.get.textDocument.similar
      .text(["AI", "machine learning"], {
        certainty: 0.65,
        moveTo: {
          concepts: ["future"],
          force: 0.5,
        },
      })
      .select("title", "text", "autoSummary", "authors", "createdAt")
      .limit(2)
      .exec();
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```graphql
    {
      Get {
        TextDocument(
          nearText: {concepts: ["AI", "machine learning"], certainty: 0.65, moveTo: {concepts: ["future"], force: 0.5}}
          limit: 2
        ) {
          _additional {
            certainty
            distance
          }
          title
          text
          autoSummary
          authors
          createdAt
        }
      }
    }
    ```
  </Tabs.Tab>
</Tabs>

<Collapse title="Response">
```typescript

[
    {
        "_additional": {
            "certainty": 0.7590836882591248,
            "distance": 0.48183262
        },
        "authors": "IJITEE;Scopus Journal;UGC Journal",
        "autoSummary": "AI is essential in engineering, leveraging ML and DL technologies. ML creates models from data, while DL automates feature extraction for large datasets. This paper explores their architectures, applications, and challenges, aiding effective AI system development and predictive analytics.",
        "createdAt": "2025-01-21T11:22:51.19Z",
        "text":"\nSee discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/364097061\n# Machine Learning and Deep Learning\n## Article in International Journal of Innovative Technology and Exploring Engineering · October 2019\n### DOI: 10.35940/ijitee.L3550.1081219\n\n | CITATIONS | READS\n | --- | ---\n | 53 | 12,797\n\n### 2 authors:\n\n | Ayushi Chahal Maharshi Dayanand University | Preeti Gulia Maharshi Dayanand University\n | --- | ---\n | 14 PUBLICATIONS | 109 CITATIONS | 122 PUBLICATIONS | 795 CITATIONS\n | --- | --- | --- | ---\n | SEE PROFILE |  | SEE PROFILE | \n\n## All content following this page was uploaded by Preeti Gulia on 04 October 2022.\n\nThe user has requested enhancement of the downloaded file.\n# Machine Learning and Deep Learning\n## Ayushi Chahal, Preeti Gulia\n\n\ Abstract: Now-a-days artificial intelligence has become an asset for engineering and experimental studies, just like statistics and calculus.\nData science is a growing field for researchers and artificial intelligence, machine learning and deep learning are roots of it.\nThis paper describes the relation between these roots of data science.\nThere is a need of machine learning if any kind of analysis is to be performed.\nThis study describes machine learning from the scratch.\nIt also focuses on Deep Learning.\nDeep learning can also be known as new trend of machine learning.\nThis paper gives a light on basic architecture of Deep learning.\nA comparative study of machine learning and deep learning is also given in the paper and allows researcher to have a broad view on these techniques so that they can understand which one will be preferable solution for a particular problem.\n\nKeywords : Machine Learning, Deep learning, Artificial Intelligence, shallow learning.\n### I. INTRODUCTION\n\nIn the era of data sciences, artificial intelligence is trying to provide human kind intelligence to the computer and for this machine learning and deep learning are the technologies which are helping artificial intelligence to do it.\nMachine Learning is the branch or subset of artificial intelligence that train the machines how to learn.\nDeep learning is confined version of machine learning.\nIt helps to raise the high standards of learning environment.\nMachine learning and deep learning both plays vital role in upgrading the computer systems to be an expert systems that can take decisions and make predictions without a human intervention.\n\nArtificial intelligence is a field which helps computer system to be intelligent and take decisions.\nMachine learning helps to implement Artificial Intelligence on the system and deep learning helps to achieve machine learning goals on the system more systematically.\nFigure 1 shows it pictorially.\n\nThis paper is divided into two parts.\nIn section II, will explain machine learning, its procedures, its applications etc.\nIn section III, Different approaches of machine learning are discussed such as deep learning and shallow learning.\n##### Revised Manuscript Received on October 30, 2019.\n- Correspondence Author Ayushi Chahal*, Department of Computer Science and Applications, Maharishi Dayanand University, Rohtak, India. \nEmail: ayushichahal@gmail.com\n\nPreeti Gulia, Department of Computer Science and Applications, Maharishi Dayanand University, Rohtak, India.\nEmail: research.mdu81@gmail.com\n\n© The Authors.\nPublished by Blue Eyes Intelligence Engineering and Sciences Publication (BEIESP).\nThis is an open access article under the CC-BY-NC-ND license http://creativecommons.org/licenses/by-nc-nd/4.0/\n\nIt describes each one’s different methods and different algorithms used by them.\nIn section IV, a comparative study between deep learning and other conventional methods of machine learning.\n\nFig. 1.\nAI, machine learning and deep learning paradigm\n### II. MACHINE LEARNING\n\nMachine learning is based on the idea that system can learn from data, identify the patterns and make decision with minimum human intervention [2].\nThis is the scientific study of algorithms and statistical models with the help of which computer system perform a specific task without using instruction, inference and patterns.\nMachine learning algorithms build mathematical model based on sample data and then make the decision.\n##### A. Machine learning procedure\n\nMachine learning incorporates four steps, given below (shown in the figure 2):\n\n- First, feature extraction - Second, selection of corresponding machine learning algorithm - Third, training and evaluation the data model’s efficiency - Four, using trained model for prediction \ Data preparation capabilities \ Basic and Advanced algorithms \ Scalability \ Various processes i.e.\nAutomation and Iterative \ Ensemble modeling\n##### B. Requirements to Create Good Machine Learning Systems:\n\nFig. 2.\nMachine learning model\n##### C. Relationship with Other Fields:\n\n | Machine learning is considered as the subset of artificial intelligence. In earlier days of AI as academic discipline, researchers were interested in having machine learn. They attempted to solve the problem with various symbolic methods as well as connectionist approach where neural network, pattern recognition are used. In 1990s, Machine learning is reorganized as a separate field. It shifted focus from symbolic approach to the methods and models of statistics and probability theory [4]. | \ Government sector: Government agencies use machine learning to mine the data for insight where agencies like public safety and utilities etc. have multiple sources of data. Sensor data analysis increases the efficiency and save money. Machine learning can also be used for security purpose i.e. help to detect fraud and to minimize the identity theft.\n | \ Relation to data mining: Both of these employ same methods often and overlap with each other. But machine learning focuses on prediction based on known properties while data mining focuses on the discovery of unknown properties. Data mining uses machine learning methods, machine learning also employs data mining methods; but with different goals or to improve the learner accuracy. | \ Retail sector: In retail sector, machine learning is used to analyze the buying history of customers. Retailers rely on machine learning to capture data, analyze and use it to personalize the shopping experience. It is also helpful to implement the marketing campaign, optimizing price, and for customer insights.\n\n\n\ Transportation: Machine learning is used to make routes more efficient and to predict the problems to increase profitability.\nIt can be done after analyzing the data to identify patterns and trends.\nData analysis and modeling aspects are key factors to delivery companies and transportation organizations.\n\n\ Relation to optimization: Machine learning is also intimated with optimization.\nLearning problems are formulated as minimization of loss function.\nLoss functions show the discrepancy between prediction of model and actual problem.\n\ Oil and gas: In this sector, machine learning is used to find new energy source and to analyze minerals in ground.\nIt is also used to predict refinery sensor failure.\nStreamlining oil distribution makes it more efficient and economic.\n\n\ Relation to statistics: It is also closely related with statistics.\nThe ideas of machine learning have had a relationship with statistics from methodological principles to theoretical tools such as the modeling paradigm.\n- E. Processes and Techniques associated with machine learning:\n\nA number of processes, techniques and methods can be applied to enhance the performance of machine learning and these are as follows:\n\n\ Feature learning\n#### D. Who’s Using Machine Learning?\n\n |  | \ | Sparse dictionary learning\n | --- | --- | ---\n | As the industries grow, large volumes of data have been recognized. For handling that data, machine learning technology is required. With the machine learning, organizations are able to work more efficiently. Machine learning is used in following areas: | \ | Anomaly detection\n | \ Decision tree\n | \ Association rules\n | F. Applications of Machine learning:\n | There are many applications of machine learning such as:\n | \ Adaptive websites\n | \ Financial services: In financial services, machine learning technology is used to identify the important insight in data and to prevent fraud. The insights help to identify investment opportunities or help investors to know when to trade. Data mining concepts also identify high risk profiles of clients or to pinpoint warning signs of fraud. |  | \ Bioinformatics \ Brain-machine interface\n\n\n\ Computer vision \ Data quality \ DNA sequence classification handwriting recognition \ Machine learning control \ Health Care: This is the major area in which wearable devices and sensors are used to assess patient’s health in real time.\nMachine learning also helps medical experts to analyze the data to identify trends.\nThis may lead to improve diagnoses and treatment.\n\ User behavior analytics etc…\n### III. MACHINE LEARNING APPROACHES\n\nBasically, Machine learning methods are broadly categorized in two categories i.e.\nShallow learning and deep learning [16].\nShallow learning basically uses neural networks with single layers or SVMs (Support Vector Machines) while deep learning uses neural network with more than one hidden layers.\nAs shown in figure 3: Fig. 3.\nDifferent approach of machine learning\n##### A. Shallow Learning\n\nShallow learning is broadly divided into two categories: Supervised and Unsupervised Learning.\nBut there are also other methods of machine learning.\nOverview of popular methods is as follows:\n\n\ Supervised learning: In supervised learning, algorithm builds a mathematical model from a set of data that contains both the input and desired outputs.(wiki) These algorithms are trained using labeled examples i.e.\ninput and desired outputs are known.\nIn this learning, algorithm receives a set of inputs along with corresponding correct outputs.\nAlgorithm learns by comparing its actual output with correct outputs to find out errors.\nThen, model is modified accordingly.\nClassification, regression, prediction and gradient boosting are the example of supervised learning which use pattern to predict the values.\nThis learning is commonly used in those applications where historical data predicts future events.\nClassification and regression are the tasks that are performed by supervised learning.\nSome examples of supervised machine learning are Nearest neighbor, Naïve Bayes, Decision Tree, Regression Tree etc.\nFigure 4 gives the pictorial view of different method of supervised learning.\n\n\ Unsupervised learning: In unsupervised learning, a mathematical model is to be built from a set of data which contains only inputs.\nDesired output labels are not present in this type of learning.\nUnsupervised learning is used against that data which doesn’t consists historical label.\nK-means, Association Rules are an example of such algorithms.\nFigure 5 describes different methods of unsupervised learning.\n\nFig. 6.\nDeep learning \ Generative models: Generative models are used for unsupervised learning.\nIt includes algorithms like Deep Belief Network (DBN), Deep auto-encoders, Deep Boltzmann (DBM).\n###### Fig. 4. Supervised Learning\n\n\ Semi-supervised learning: In some cases, input may be only partially available, or restricted to special feedback.\nAt that time, these algorithms are used.\nThese are used to develop mathematical model from incomplete training data, where a portion of the sample input doesn’t consist labels.\nThis learning is useful when cost of labeling is too high to allow for fully labeled training process.\n\n\ Reinforcement learning: This is the area of learning concerned with how software agents take actions in an environment to maximize the cumulative reward.\nIn this type of learning, a feedback is to be given in the form of positive or negative reinforcement in a dynamic environment.\nThese are commonly used in autonomous vehicle or in learning to play game against human opponent [3].\nQ-learning is an example of reinforcement learning.\n\n\ Active learning: Desired outputs are accessed for a limited set of inputs.\nIn this learning, the inputs are based on budget, and optimize the choice of inputs for which output will be acquired.\n\n\ Meta learning: Here, algorithms learn their own inductive bias based on previous experiences.\nSome examples of meta learning are Bagging, Boosting, Random Forest.\n\nFig. 5.\nUnsupervised Learning\n##### B. Deep Learning\n\nDeep learning is a set of algorithms of machine learning which uses multiple layers that corresponds to different level of abstraction to each level.. It consists of input layer, output layer and several hidden layer.\nIt is used for voice synthesis, image processing, handwriting recognition, object detection, prediction analytics and decision making.\n[10] Deep learning can be broadly classified into three types (figure 6):\n- C. Deep Learning architecture\n\n | \ Discriminative models: | Discriminative models usually provide supervised learning approaches. It involves Convolution Neural Network (CNN), Deep Stacking Network (DSN). | Deep Learning consists of supervised or unsupervised learning techniques based on many layers of artificial neural networks that are able to learn hierarchical representations in deep architectures. [11] It is extended version of artificial neural network. Deep Learning architectures consist of multiple processing layers. Each layer is able to produce non-linear responses based on the data from its input layer.\n | --- | --- | ---\n | \ Hybrid models: Hybrid models incorporate the benefits of both discriminative and generative models. Deep Neural network (DNN) is an example of hybrid models. |  | The functionality of Deep Learning is imitated from the mechanisms of human brain and neurons for processing of\n\n#### Fig. 8. Deep Neural network\n\nsignals.\nDeep Learning architectures have gained more attention in recent years compared to the other traditional machine learning approaches.\nSuch approaches are considered as being shallow-structured learning architectures versions (i.e., a limited subset) of Deep Learning.\n\nA Deep Neural Network consists of an input layer, severalhidden layers, and an output layer.\nEach layer includes severalunits called neurons.\nThese neurons are also called as artificial neurons.\nA neuron receives several inputs, performs a weighted summation over its inputs, then the resulting sum goes through an activation function to produce an output.\n\nEach neuron has a vector of weights associated to its input size as well as a bias that should be optimized during the training process.\nFigure 7 below shows the structure of neuron.\n#### Fig. 7. Structure of a neuron\n\nWhen these artificial neurons are assigned sequentially which makes a chain as one neurons output becomes input of next neuron, and this process goes on over and over which makes a Artificial Neural Network.\nDeep Learning Neural Networks consists of more than one hidden layer as shown below in figure 8.\n### IV. DEEP LEARNING COMPARISON WITH CONVENTIONAL MACHINE LEARNING TECHNIQUES\n\nDeep learning is a new era of machine learning.\nDeep learning includes both supervised and unsupervised learning paradigm of machine learning.\nMachine learning and deep learning helps in providing intelligence to the system that can make prediction for future using past data.\n[12] \ Conventional machine learning algorithms can’t learn directly from the raw data.\nThey need careful engineering to carefully extract features from raw data and highly classified domain expertise, which are further used to in internal representations to identify these feature’s patterns.\nIn Deep Learning, first step of machine learning procedure is not present.\nThis step is automated in deep learning.\nDeep Learning can extract new features automatically from raw data.\nFigure 9 shows this point clearly [13].\n\nFig. 9.\nFeature extraction is automated in deep learning\n\n\ Deep learning algorithms work more accurately on large Data set as compared to conventional machine learning algorithms.\nWhile machine learning algorithms outperforms deep learning in case of small or medium size datasets.\n[14] \ Deep learning algorithms take less time to infer a problem as compared to conventional machine learning algorithms \ Deep learning performs a high amount of matrix multiple hence it needs powerful engine preferably GPU (Graphical Processing Units) or specially designed TPU (Tensor Processing Units) while other conventional machine learning algorithms can work on low end machines.\n\n\ Deep learning algorithms are difficult to impossible to interpret.\nSome of the machine learning algorithms like (logistics, decision tree) can be interpreted easily while some (like SVM) are almost impossible to interpret.\n[15] \ Training time for data to create the model is more in deep learning as compared to other machine learning algorithms.\n### V. CONCLUSION\n\nThis article examined the concepts of machine learning.\nMachine learning has gained a lot of attention of researchers nowadays due to its distinct features.\nFirstly, the article specified the points to make a good machine learning system.\nFollowed by this, the usage and applications of machine learning have been discussed in this article.\nHowever the road of machine learning is not as simple as it looks to be.\nThere are some challenges in this area to get the expected results such as lack of suitable data, data bias, and lack of resources, privacy problems and evaluation problems.\nThis paper crates a broad view for a researcher for machine learning by categorizing it into two parts, namely: shallow learning and deep learning.\nSupervised and unsupervised machine learning concepts are supposed to be in the category of shallow learning as these techniques use less number of hidden layers or SVMs.\nWhile deep learning is considered as a different category, because of its deep layered architecture discussed in the article.\n\nDeep learning is a growing field in a sector of predictive analytics.\nThis paper provides a comparative study of conventional methods of machine learning and deep learning which helps new researchers to choose which technique would be right to apply in a particular environment.\nSuch as, if one is working on small training data set then he must use machine learning algorithms rather than deep learning while, if dataset needed to choose the features then one must use machine learning technique because in case of deep learning this feature selection procedure is automated researcher do not have to bother about it.\nThis paper creates base for the researcher who wants to pursue research in field of artificial intelligence or predictive analytics.\n#### REFERENCES\n- 1. https://en.wikipedia.org/wiki/Machine_learning\n- 2. https://www.sas.com › SAS Insights › Analytics Insights\n##### 3. Bishop, C\n- M. (2006), Pattern Recognition and Machine Learning, Springer, ISBN 978-0-387-31073-2\n- 4. 11.\nLangley, Pat (2011).\n\"The changing science of machine learning\".\nMachine Learning.\n82 (3): 275– 279.\nDoi:10.1007/s10994-011-5242-y\n##### 5. Alpaydin, Ethem (2010)\n\nIntroduction to Machine Learning.\nMIT Press.\np. 9.\nISBN 978-0-262-01243-0\n##### 6. Why Machine Learning Models Often Fail to Learn: QuickTake Q&A\"\n\nBloomberg.com.\n2016-11-10.\nRetrieved 2017-04-10.\n- 7. \"The First Wave of Corporate AI Is Doomed to Fail\".\nHarvard Business Review.\n2017-04-18.\nRetrieved 2018-08-20.\n- 8. \"Why the A.I.\neuphoria is doomed to fail\".\nVentureBeat.\n2016-09-18.\nRetrieved 2018-08-20.\n- 9. \"9 Reasons why your machine learning project will fail\".\nwww.kdnuggets.com.\nRetrieved 2018-08-20.\n##### 10. P\n\nP. Kuang, W.-N.\nCao, and Q. Wu, “Preview on structures and algorithms of deep learning,” in 2014 11th International Computer Conference on Wavelet Actiev Media Technology and Information Processing(ICCWAMTIP), Chengdu, China, 2014, pp.\n176–179.\n##### 11. L\n\nL. Deng, “Deep Learning: Methods and Applications,” Found.\nTrends® Signal Process., vol.\n7, no. 3–4, pp.\n197–387, 2014.\n##### 12. J\n- J. L. Berral-García, “When and How to Apply Statistics, Machine Learning and Deep Learning Techniques,” in 2018 20th International Conference on Transparent Optical Networks (ICTON), 2018, pp.\n1–4.\n##### 13. J\n\nJ. Latif, C. Xiao, A. Imran, and S. Tu, “Medical Imaging using Machine Learning and Deep Learning Algorithms: A Review,” in 2019 2nd International Conference on Computing, Mathematics and Engineering Technologies (iCoMET), 2019, pp.\n1–5.\n##### 14. N\n- N. G. Paterakis, E. Mocanu, M. Gibescu, B. Stappers, and W. van Alst, “Deep learning versus traditional machine learning methods for aggregated energy demand prediction,” in 2017 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT-Europe), 2017, pp.\n1–6.\n##### 15. M\n\nM. Sewak, S. K. Sahay, and H. Rathore, “Comparison of Deep Learning and the Classical Machine Learning Algorithm for the Malware Detection,” in 2018 19th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD), 2018, pp.\n293–296.\n##### 16. A\n\nA. Jabeen, N. Ahmad, and K. Raza, “Machine Learning-based state-of-the-art methods for the classification of RNA-Seq data,” Bioinformatics, preprint, Mar.\n2017.\n#### AUTHORS PROFILE\n\nMs. Ayushi Chahal has completed her M.Tech from GJUS&T University.\nShe is currently pursuing Ph.D. in Computer Science at Department of Computer Science & Applications, M.D.University, Rohtak.\nHer main research area includes network security, Internet of Things (IoT), Machine Learning.\n\nDr. Preeti Gulia is currently working as Assistant Professor at Department of Computer Science & Applications, M.D.University, Rohtak, India.\nShe is serving the Department since 2009.\nShe earned her doctoral degree in 2013.\nShe has published more than 65 research papers and articles in journal and conferences of National/ International repute including ACM, Scopus.\nHer area of research includes Data Mining, Big Data, Machine Learning, Deep Learning, IoT, Software Engineering.\nShe is an active professional member of IAENG, CSI and ACM. She is also serving as Editorial Board Member Active Reviewer of International/ National Journals.\nShe has guided one research scholar as well as guiding four Ph.D. research scholars from various research areas View publication stats",
        "title": "International Journal of Innovative Technology and Exploring Engineering (IJITEE)"
    },
    {
        "_additional": {
            "certainty": 0.6899665892124176,
            "distance": 0.6200668
        },
        "authors": [
            {
                "name": "Amir Houieh",
                "link": "https://www.linkedin.com/in/amirhouieh/",
                "image": "amir.png"
            }
        ],
        "autoSummary": "Unbody offers an effortless AI app development with a headless API and modular AI pipeline for integrating diverse data types. It tackles personalization, data handling, and complexity, delivering user-centric and AI-enhanced applications. Sign up for free!",
        "createdAt": "2025-01-21T10:34:57.752Z",
        "text": "From this point on, everyone —yes, everyone— wants apps that understand their data like humans.\n But making A.I. apps isn't easy.\n The real challenge is in the development process.\n Creating AI apps is tough. Seriously though. And if you're a developer, you know exactly what I mean. If I got you interested keep reading because, in the end, you as a non-ai developer would not feel excluded from AI development.\n Big elephant in the room\n Remember when ChatGPT hit the scene? Suddenly, AI wasn't just for techies. It showed everyone the power of AI, making us all want more human-like interactions with our apps. We're not just talking about faster data processing; we're talking about apps that understand and respond like a person. That's a game-changer.\n But here's the kicker: blending these AI capabilities with your unique content? That's where it gets hairy. And that’s what's driving this whole new shift in how we interact with technology.\n Challenge 1 - Personalisation\n We've all been amazed by AI's chat prowess, right? But when it comes to really getting personal, things get tricky. These AIs are schooled in general knowledge, thanks to being fed loads of public data. But your data? That's a different story. It's unique, private, and not something these AI models are familiar with.\n It's not just feeding them data; it's teaching them to recognize the subtleties that make your data distinct. This leap from generic to personal is tough. We’re talking about a system that needs to be smart enough to adapt to your specific needs, all while keeping things private and secure. That's a tall order.\n Challenge 2 - Your data: where it lives and its many faces\n Now, let's talk about your own data. We expect AI to understand it, but first, we need to see where this data actually lives and in what shape it is. Our digital lives are scattered – emails, Dropbox, Google Drive, social media, Slack, Discord, local devices... it's a kaleidoscope of data forms. And AI? It struggles with this mishmash.\n Each data type – text, images, audio – has its own language, and they're stored in different corners of our digital world. For AI to really make sense of it, it needs to be a jack-of-all-trades. And that's no small feat. The challenge is to make AI savvy enough to navigate and understand these varied data landscapes without making us change our habits. After all, we want AI to fit into our lives, not the other way around.\n Challenge 3 - The developer's tightrope\n A regular tech stack for a simple chatbot - from @aigeek__\n So, we've talked about the challenges of personalizing AI and dealing with our scattered, diverse data. But here's where things really get interesting for developers. This is where the rubber meets the road.\n Diving into the heart of AI app development, developers face quite a puzzle. Picture this: you're building a chatbot drawing data from Google Drive and Slack. You start mixing tools like LangChain, vector databases, and LlamaIndex with a dash of RAG APIs and vectorizers. Before you know it, you're juggling query languages and document parsers. It's like opening a toolbox and finding tools you never knew existed. You see, this is already getting out of hand, isn't it?\n The decisions you have to make when it comes to building LLM app - Jery liu - CEO of LlamaIndex\n The real trick is not just understanding these tools but making them play nicely together. It's a bit like conducting an orchestra where each musician is playing a different tune. That's the challenge here, and it's exactly why Unbody was born – to make this symphony a bit more harmonious, turning what could be a tech headache into a more manageable and even fun endeavor in AI app development.\n Tying it all together: the cascade of challenges\n Now, let's take a step back and see how these challenges are interconnected, leading to a pivotal pain point for developers. First, we have the personalization challenge – making AI understand your unique data. Then comes the issue of diverse data storage and formats. These two combine to form a complex landscape that developers must navigate. Add to this the intricate web of AI tools and technologies, and you have a perfect storm. It's a cascade of challenges, each feeding into the next, culminating in a significant hurdle: making AI practical and accessible for all developers, not just the AI gurus.\n Before we dive into how Unbody simplifies this, let's decode some buzzwords. This way, we're all on the same page, and you won't feel lost in the AI jargon jungle.\n LLM (Large Language Model): Think of LLMs as the brain behind AI that understands and generates human-like text. They're the wizards of language, trained to interpret and respond just like a person would.\n RAG (Retrieval-Augmented Generation): This is like giving AI a research assistant. RAG helps AI pull in extra information from user's various data sources to make its responses even smarter.\n ML (Machine Learning): ML is where computers learn from data to make decisions and predictions. It's like teaching a computer to think and learn from experience.\n Vectorizing and Embeddings: This is about converting different types of data (like text or images) into a format that AI can understand and work with. Think of it as translating human language into AI language.\n Multimodal: This refers to AI's ability to understand and process more than one type of data – like text, images, and sound – all at once.\n Vector Database: Imagine a super-smart library where AI can store and retrieve complex data. Vector databases are designed for the kind of multi-dimensional data that AI needs to function effectively.\n With this foundation laid, we're ready to dive into how Unbody addresses these challenges, making AI app development not just a possibility but a pleasure for all developers.\n Let’s put all fancy words in one box\n Still with me? Navigating AI development can seem daunting, but that's exactly why Unbody is here. Our solution is straightforward; we put all those complex AI terms and intricate tasks into one, magical box. Think of Unbody as an invisible AI layer, a headless API: just tell Unbody where your data lives — any place, any format — and she takes it from there. Unbody will automatically aggregate, sync, and transform your data into advanced AI functionalities, all accessible through a single GraphQL endpoint.\n Now, let's delve a bit deeper and peek under the hood. When you're building an app or setting up an integration with Unbody, it unfolds over four layers. And don’t worry, many of these layers work seamlessly in the background, streamlining your workflow without overcomplicating it.\n 4 layers of a seamless modular AI pipeline from private data to frontend\n Layer 1: Data Aggregation and Integration\n At the core of Unbody's first layer is the seamless aggregation of your data, setting a strong foundation for the advanced AI processing that follows.\n layer 1: connect your data to unbody\n Telling Unbody where your data, takes 4 simple clicks!\n Third-Party Integrations: Unbody effortlessly connects with a variety of platforms. Whether your data is on Google Drive, Discord, Slack, or local folders on your desktop, Unbody integrates seamlessly.\n Versatile Data Handling: Unbody is equipped to handle a wide range of data formats. From PDFs and text documents to Markdown, JPEGs, videos, and audio files, Unbody ensures that your data, in all its forms, is comprehensively covered and ready for the next stages.\n Evolving with Your Input: Our commitment to meeting your development needs is ongoing. We maintain an extensive and ever-expanding list of supported providers and data types. Your feedback and suggestions on our GitHub are crucial; they guide our roadmap and help us prioritize new integrations and capabilities.\n Layer 1 is where your journey with Unbody begins, ensuring that all your data, regardless of where it resides or its format, is meticulously gathered and prepared for the sophisticated AI operations that Unbody facilitates.\n Layer 2: AI data processing and enhancement\n Layer 2 is where AI magic happens. This is the stage where the advanced functionalities of Large Language Models (LLMs) and Retrieval Augmented Generation (RAG) come into play. But what exactly goes on in this layer? Let's delve into the key tasks that make Layer 2 a powerhouse of AI activity.\n Data Transformation: Layer 2 handles the transformation of your raw data into formats that AI can understand and use. This involves breaking down different types of content - text, images, audio, and video - into a form suitable for AI processing.\n Modular Approach for Customization: Understanding that one size doesn’t fit all in AI, Unbody adopts a modular approach in this layer. This means you, as the user, can choose from different vectorizers and LLMs for different types of inputs. For example:\n Layer 2: compose your favorite AI engines for all data types; text, image, audio and video\n For Text: Options might include popular LLMs like OpenAI's GPT models.\n For Images: Tools are available to turn images into searchable and analyzable data.\n For Multimodal Data: Unbody provides solutions that can handle a mix of text, images, and more.\n Beyond Basic Vectorization: But it's not just about converting data into AI-readable formats. Layer 2 also takes care of complex tasks like applying image captioning, auto transcription, and more. These additional tools and functionalities ensure that your application is not just intelligent but also versatile and capable of handling a variety of AI-driven tasks.\n In short, Layer 2 is where your data undergoes a significant transformation, becoming a rich resource for AI applications. It's about taking the complexity of AI processing and making it manageable and customizable for your specific needs.\n Layer 3: Delivery and interaction\n Layer 3 marks the exciting phase where the magic of AI processing comes to fruition, and your data is now ready for interaction. This stage is all about delivering the processed data through Unbody's robust APIs, enabling you to tap into a range of enhanced AI functionalities.\n Content API (GraphQL)\n Our primary touchpoint, the Content API, uses GraphQL. It provides a direct and powerful way for you to interact with your enhanced data. The GraphQL interface simplifies complex queries, making data retrieval both efficient and precise. While this post will demonstrate examples using GraphQL, remember that our SDKs are also available for deeper and more integrated solutions. Read more about our SDKs here.\n With Unbody's GraphQL endpoints, you get straightforward access to AI functionalities, including:\n Basic content retrieval: Anything you would expect from a rest API and a database, from getting multiple documents to filters to sorts and pagination. read more → []\n Semantic Search: Dive deep into the meaning behind words and phrases in your data\n Generative search\n Q&A: Provide direct answers to queries using your data.\n Generative Search: Create new content or find connections within your data.\n Visual Search: Harness AI to search and analyze visual content.\n We are working hard to deliver even more: - Chat: Engage in intelligent and context-aware conversations. - Classification: Categorize and organize your data smartly. - Summarization: Get concise summaries of larger text bodies. - Entity Extraction: Identify and extract key information.\n Additional APIs for enhanced functionality\n Image API (Powered by Imgix)\n Our Image API, powered by Imgix, offers a range of tools for image processing and manipulation, enriching your applications with powerful image handling capabilities. Explore more about the Image API here.\n Video API (Powered by Mux)\n This API, in collaboration with Mux, brings advanced video functionalities to your fingertips. More details on Video API capabilities here.\n Layer 3 is where you, as a developer, begin to see the practical applications of all the AI processing done in the previous layers. It’s the stage where your data, now fully processed and AI-enhanced, becomes an interactive asset, ready to be used in a myriad of innovative ways.\n Layer 4: Application realization & use-cases\n Layer 4 is the stage where all the Unbody magic you've seen so far really takes shape. This is where the AI-enhanced data, meticulously processed in the previous layers, transforms into something tangible and interactive for your users.\n Now it is time to create intuitive and engaging interfaces for users to interact with the AI capabilities. It's where your creativity as a developer shines, leveraging the processed data to build unique applications.\n Real-World Use Cases of Unbody\n Unbody’s applications fall into two major categories:\n AI use-cases:\n Semantic search: Enhance search capabilities with contextually aware results.\n Visual search: Implement advanced image search functionalities.\n Generative search: Create content or find connections within data.\n Chatbots and private AI assistants: Develop conversational agents for various purposes.\n Q&A systems: Build systems that provide direct answers from large datasets.\n These functionalities enable you to integrate sophisticated AI solutions into your applications.\n Intelligent content management:\n Unbody enabled IsiaUrbino platform to offer their students to use google drive as their CMS - isiaurbino.net\n Unbody can serve as a next-generation solution for managing website content and data, replacing traditional headless CMSs. It offers an intuitive and intelligent way to handle content, making it more responsive and context-aware. [Read more about using Unbody as an intelligent content management system in our other blog post].\n Layer 4 marks the culmination of Unbody’s AI processing, where developers can harness its full potential to deliver innovative applications and solutions that are not just smart but also user-centric.\n The end beginning\n I think this is it! 🌟\n I hope this post has shed some light on the challenges of AI development and how Unbody might just be the ally you need on this journey.\n A huge shout-out to the amazing team at Weaviate, the powerhouse engine behind Unbody! 💛\n Whether you choose to use Unbody or blaze your own trail, I encourage you to dive into AI development. The gap between tech capabilities and practical applications is vast, and your creativity is key to bridging it. Don't let the jargon deter you – let's innovate together! 💡\n Interested in joining the Unbody adventure? That's what Xbody is all about! Check it out and see how you can be a part of our community of change-makers. 🌐\n Last but not least, our freemium plan is available for you to try out Unbody for free. Sign up here and start building your AI applications today! 🚀\nLast but not least, our freemium plan is available for you to try out Unbody for free. Sign up here and start building your AI applications today! 🚀",
        "title": "Unbody: all AI buzz in one endpoint, one line of code"
    }
]
```
</Collapse>

## Image Similarity
The code demonstrates visual search capabilities through the `.similar.image()` method. Operating on the `imageBlock` collection, it finds the top 5 visually similar images matching a reference URL, with a certainty threshold of 0.65 for accuracy. Learn more in our [Visual Similarity Guide](/content-api/search/visual-similarity).

<Tabs items={['Unbody SDK', 'GraphQL']}>
  <Tabs.Tab>
    ```typescript
    const {
      data: { payload },
    } = await unbody.get.imageBlock.similar
      .image(
        "https://www.treadfirst.co.uk/wp-content/uploads/2023/05/riseBlog.jpg",
        {
          certainty: 0.65,
        }
      )
      .select("originalName", "url")
      .limit(5)
      .exec();
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```graphql
     query {
        Get {
          ImageBlock(
            nearImage: {
              image: "https://www.treadfirst.co.uk/wp-content/uploads/2023/05/riseBlog.jpg"
              certainty: 0.65
            }
            limit: 5
          ) {
            _additional {
              certainty
              distance
            }
            originalName
            url
          }
        }
      }

    ```
  </Tabs.Tab>
</Tabs>

<Collapse title="Response">
```typescript

[
    {
        "_additional": {
            "certainty": 0.8785399794578552,
            "distance": 0.24292004
        },
        "originalName": "image2.jpeg",
        "url": "https://images.cdn.unbody.io/1052215a-e6b0-4e78-86d1-b928e6aaadfc/image/6f07d51f-3211-5397-b7a3-fec2d3fdcec8.jpeg"
    },
    {
        "_additional": {
            "certainty": 0.8606066107749939,
            "distance": 0.27878678
        },
        "originalName": "2020-Honda-e-Charging-Point-01.jpeg",
        "url": "https://images.cdn.unbody.io/1052215a-e6b0-4e78-86d1-b928e6aaadfc/image/65a192c9-308e-55a1-9cda-5dcd57e77524.jpeg"
    },
    {
        "_additional": {
            "certainty": 0.8560068905353546,
            "distance": 0.28798622
        },
        "originalName": "images (2).jpeg",
        "url": "https://images.cdn.unbody.io/1052215a-e6b0-4e78-86d1-b928e6aaadfc/image/883130f5-1b9d-5987-ad22-d59a3892d5d1.jpeg"
    },
    {
        "_additional": {
            "certainty": 0.8525442183017731,
            "distance": 0.29491156
        },
        "originalName": "6_0.jpeg",
        "url": "https://images.cdn.unbody.io/1052215a-e6b0-4e78-86d1-b928e6aaadfc/image/154d015d-034d-528a-903d-bc1163841479.jpeg"
    },
    {
        "_additional": {
            "certainty": 0.8517109751701355,
            "distance": 0.29657805
        },
        "originalName": "Honda_e-3.jpeg",
        "url": "https://images.cdn.unbody.io/1052215a-e6b0-4e78-86d1-b928e6aaadfc/image/65c31cc7-ef8f-5c07-a547-6bdd21b1642a.jpeg"
    }
]
```
</Collapse>

## Record Similarity
Demonstrating record-based similarity search, this example uses a specific record ID to find related content. The `.similar.record()` method filters results with a 0.75 certainty threshold and limits to 5 matches, ensuring relevance. Learn more in our [Record Similarity Guide](/content-api/search/record-similarity).

<Tabs items={['Unbody SDK', 'GraphQL']}>
  <Tabs.Tab>
    ```typescript
    const {
      data: { payload },
    } = await unbody.get.textDocument.similar
      .record("201704f2-1aee-53bc-b6d2-463baf3f160f", {
        certainty: 0.75,
      })
      .select("title", "originalName", "autoSummary", "authors")
      .limit(5)
      .exec();
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```graphql
    query {
        Get {
          TextDocument(
            nearObject: {
              id: "201704f2-1aee-53bc-b6d2-463baf3f160f"
              certainty: 0.75
            }
            limit: 5
          ) {
            _additional {
              certainty
              distance
            }
            title
            originalName
            autoSummary
            authors
          }
        }
    }
    ```
  </Tabs.Tab>
</Tabs>

<Collapse title="Response">
```typescript

[
    {
        "_additional": {
            "certainty": 0.9999997019767761,
            "distance": 5.9604645e-7
        },
        "authors": "",
        "autoSummary": null,
        "originalName": "Quentin Tarantino_ Master of Cinematic Artistry.docx",
        "title": ""
    },
    {
        "_additional": {
            "certainty": 0.9096074402332306,
            "distance": 0.18078512
        },
        "authors": "",
        "autoSummary": null,
        "originalName": "Quentin Tarantino and Diego Maradona_ A Tale of Two Mavericks.docx",
        "title": "Quentin Tarantino and Diego Maradona: A Tale of Two Mavericks"
    },
    {
        "_additional": {
            "certainty": 0.8034366071224213,
            "distance": 0.3931268
        },
        "authors": "",
        "autoSummary": null,
        "originalName": "The Rise of Electric Vehicles in Urban Environments.docx",
        "title": "The Rise of Electric Vehicles in Urban Environments"
    },
    {
        "_additional": {
            "certainty": 0.7638762593269348,
            "distance": 0.47224748
        },
        "authors": "",
        "autoSummary": null,
        "originalName": "Overcoming Challenges in the Adoption of Electric Vehicles_ A Roadmap for Urban Transformation.docx",
        "title": "Overcoming Challenges in the Adoption of Electric Vehicles: A Roadmap for Urban Transformation"
    }
]
```
</Collapse>