import Collapse from '@/components/Collapse'

# Image Analysis Enhancement Pipeline

When working with images in your application, you need to automatically extract and structure metadata like colors, subjects, and resolution. This is essential for:
- Building searchable image libraries
- Creating intelligent image tagging systems
- Automating image categorization

```typescript copy
import { Enhancement, ProjectSettings, TextVectorizer, ImageVectorizer, 
         Generative, AutoSummary, AutoVision, CustomSchema } from 'unbody/admin';
import { StringField, IImageBlock } from 'unbody';

// 1. Create the enhancement pipeline for image analysis
const imageEnhancementPipeline = new Enhancement.Pipeline(
  "enrich_image",  
  "ImageBlock",    
);

// 2. Define metadata extraction step using openai-gpt-4o
const extractImageInfo = new Enhancement.Step(
  "extract_image_info",
  new Enhancement.Action.StructuredGenerator({
    model: "openai-gpt-4o",
    
    prompt: (ctx) => `
      Analyze this image and extract colors, subjects, resolution:
      Image Url: ${ctx.record.url || "None"}
      Caption: ${ctx.record.caption || "No caption"}
      Width: ${ctx.record.width}
      Height: ${ctx.record.height}
      size in bytes: ${ctx.record.size}
    `,
    // using zod schema 
    schema: (ctx, { z }) =>
      z.object({
        colors: z.array(z.string()).describe("Main colors in the image"),
        subjects: z.array(z.string()).describe("Main subjects or objects"),
        resolution: z.string().describe("resolution of the image"),
      }),
  }),
  {
    output: {
      xColors: (ctx) => JSON.stringify(ctx.result.json.colors),
      xSubjects: (ctx) => JSON.stringify(ctx.result.json.subjects),
      xResolution: (ctx) => ctx.result.json.resolution,
    },
  }
);

// 3. Add extraction step to pipeline
imageEnhancementPipeline.add(extractImageInfo);

// 4. // 4. Configure a project with the enhancement pipeline and other settings
const enhancement = new Enhancement();
enhancement.add(imageEnhancementPipeline);

const projectSettings = new ProjectSettings();
projectSettings
  .set(new TextVectorizer(TextVectorizer.OpenAI.TextEmbedding3Small))
  .set(new ImageVectorizer(ImageVectorizer.Img2VecNeural.Default))
  .set(new Generative(Generative.OpenAI.GPT4o))
  .set(new AutoSummary(AutoSummary.OpenAI.GPT4o))
  .set(new AutoVision(AutoVision.OpenAI.GPT4o))
  .set(new PdfParser(PdfParser.NlmSherpa.Default))
  .set(enhancement);

// 5. Create project with extended ImageBlock schema
const project = admin.projects.ref({
    name: "Image Analysis Project",
    settings: projectSettings,
});

project.settings.set(
    new CustomSchema().extend(
    new CustomSchema.Collection("ImageBlock")
        .add(new CustomSchema.Field.Text("xColors", "Main colors detected in the image"))
        .add(new CustomSchema.Field.Text("xSubjects", "Main subjects or objects detected"))
        .add(new CustomSchema.Field.Text("xResolution", "Resolution information"))
    )
);

await project.save();

// 6. Query enhanced images with type safety
interface ExtendedImageBlock extends IImageBlock {
  xColors: StringField;
  xSubjects: StringField;
  xResolution: StringField;
}

const { data: { payload } } = await unbody.get
  .collection<ExtendedImageBlock>("ImageBlock")
  .select("originalName", "xColors", "xSubjects", "xResolution")
  .exec();

console.log(payload)  
```

<Collapse title="Response">

```typescript copy
[
    {
        "originalName": "sample.jpg",
        "xColors": "[\"blue\",\"green\",\"black\"]",
        "xResolution": "1440x960",
        "xSubjects": "[\"classic car\",\"country road\",\"person\"]"
    }
    // ... more image entries
]
```
</Collapse>

## Related Resources
- [Enhancement Pipeline Documentation](/project-configurations/enhancers)
- [Custom Schema Guide](/project-configurations/custom-schemas)